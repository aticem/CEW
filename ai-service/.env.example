# AI Service Configuration
PORT=3001
NODE_ENV=development
LOG_LEVEL=info

# Anthropic Configuration (for LLM - PRIMARY)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
# Preferred model (will automatically fallback if unavailable)
ANTHROPIC_PREFERRED_MODEL=claude-sonnet-4-5
# Fallback model (guaranteed stable model)
ANTHROPIC_FALLBACK_MODEL=claude-3-5-sonnet-20241022

# OpenAI Configuration (for embeddings ONLY - NOT for LLM)
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Vector Database Configuration (choose one)
VECTOR_DB_PROVIDER=qdrant
# VECTOR_DB_PROVIDER=pinecone

# Qdrant Configuration (local/cloud)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=cew_documents

# Pinecone Configuration (if using Pinecone)
PINECONE_API_KEY=
PINECONE_ENVIRONMENT=
PINECONE_INDEX_NAME=cew-documents

# Chunking Configuration
CHUNK_SIZE=500
CHUNK_OVERLAP=50
MIN_CHUNK_SIZE=100

# Rate Limiting
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=100

# CORS Configuration
CORS_ORIGIN=http://localhost:5173

# Document Storage
DOCUMENTS_PATH=./documents
